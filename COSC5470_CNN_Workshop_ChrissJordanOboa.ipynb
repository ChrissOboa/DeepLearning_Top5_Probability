{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV9LBf4nBDg_"
      },
      "source": [
        "# CNNs in PyTorch\n",
        "\n",
        "In this assignment, you'll implement some Convolutional Neural Networks (CNNs) in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppx9vYd7U9fu"
      },
      "source": [
        "## Setting up\n",
        "\n",
        "We'll start by importing the following:\n",
        "- [`torch`](https://pytorch.org/docs/stable/torch.html) - the core PyTorch library.\n",
        "- [`torch.nn`](https://pytorch.org/docs/stable/nn.html) - a module containing building blocks for NNs such as linear layers, convolutional layers, and so on.\n",
        "- [`torch.nn.functional`](https://pytorch.org/docs/stable/nn.functional.html) - a module containing activation functions, loss functions, and so on.\n",
        "- [`torch.optim`](https://pytorch.org/docs/stable/optim.html) - a module containing optimizers which update the parameters of a NN.\n",
        "- [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) in [`torch.utils.data`](https://pytorch.org/docs/stable/data.html) - Can be used to batch data together and iterate over batches, shuffle data, and parallelize the training process to speed it up.\n",
        "- [`MNIST`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html) in [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) - The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is a collection of images of handwritten digits.\n",
        "- [`ToTensor`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor) in [`torchvision.transforms`](https://pytorch.org/vision/0.9/transforms.html) - Converts PIL images or NumPy arrays to PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l74HSkVDtdzo"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision.transforms.v2 import ToTensor\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcSEpkOcA6p"
      },
      "source": [
        "## Data\n",
        "\n",
        "Let's define a transformation for the [CIFAR10 dataset](https://en.wikipedia.org/wiki/CIFAR-10).\n",
        "\n",
        "We'll first cast the images to PyTorch tensors using [`transforms.ToTensor()`](https://pytorch.org/vision/master/generated/torchvision.transforms.ToTensor.html). These tensors are automatically normalized such that their values are between 0 and 1.\n",
        "\n",
        "Then, we'll re-normalize the pixel values with [`transforms.Normalize()`](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html) to conform approximately to a standard normal distribution, assuming the mean and standard deviation of any channel of the returned tensor to be 0.5. This is not an unreasonable assumption. It's also a fairly standard thing to do to squash inputs to be in (or close to) the range [-1,1], which is where neural networks work best in terms of converging when performing optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OjvbG0f7hF3N"
      },
      "outputs": [],
      "source": [
        "# CIFAR-10 transform - three channels, normalize with 3 means and 3 SDs\n",
        "cifar_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# MNIST transform - single channel, so only 1 mean and 1 SD\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1308,), (0.3016,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RI612Kn8jUX"
      },
      "source": [
        "Let's load up the CIFAR-10 dataset. You can specify the split you want using `train=True|False`. `root` is the directory where the dataset will be saved. You can also directly apply the transform from the previous cell by specifying `transform`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob7JPEEabfTR",
        "outputId": "3436f3ef-7e4b-4ed3-c33c-2360cf51fadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 46767535.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# CIFAR10 data\n",
        "train_dataset = CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=cifar_transform\n",
        ")\n",
        "\n",
        "val_dataset = CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=cifar_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb2XIf19cnsq"
      },
      "source": [
        "Let's define `DataLoader` objects for the CIFAR10 data now.\n",
        "\n",
        "We'll use a (mini) batch size of 32. It's common to use powers of 2 in deep learning because it's more efficient to handle such numbers on hardware.\n",
        "\n",
        "We'll define separate `DataLoader` objects to handle our training and test splits to avoid data leakage (training on the test set or testing on the train set).\n",
        "\n",
        "We'll also have the `DataLoader` objects shuffle our data whenever we iterate over them (`shuffle=True`). Shuffling data at each epoch is beneficial in that the model won't be optimized in a way that depends on a specific ordering of the data.\n",
        "\n",
        "Finally, we'll parallelize the loading of the data using 4 CPU processes to load data (`num_workers=4`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "93SCDUnGji8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8996854-2d69-4577-b60a-8771c0d304d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# dataloaders\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZpzVZUjcJSi"
      },
      "source": [
        "## Defining and training CNNs\n",
        "\n",
        "We'll define `criterion` to be [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), a common loss function used to train classification models.\n",
        "\n",
        "We'll also define a Stochastic Gradient Descent optmizizer ([`optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)), which will optimize the parameters of `net`. We'll set two hyperparameters manually: the learning rate (`lr=0.001`) and the momentum (`momentum=0.9`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yNEwqv8rkQNM"
      },
      "outputs": [],
      "source": [
        "# Loss fuction and optimizer\n",
        "def get_crit_and_opt(net):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    return criterion, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1kVjROgsGyF"
      },
      "source": [
        "Let's see how [LeNet5](https://ieeexplore.ieee.org/document/726791) (Lecun et al. 1998) is implemented. The architecture looks something like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-mgpop1bcN7"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1PwYfmSXqBnosIQi-ewrr03Ibd_lmRtea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAbXzjDJsrWb"
      },
      "source": [
        "LeNet5 is compatible with the MNIST dataset. Let's see how to implement the architecture in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3wg7aZ5PFfem"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        # 6 input channels to 16 output channels with 5x5 convolution\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # affine operations: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 16 channels each of size 5x5 to 1x120 vector\n",
        "        self.fc2 = nn.Linear(120, 84) # 1x120 vector to 1x84 vector\n",
        "        self.fc3 = nn.Linear(84, 10) # 1x84 vector to 1x10 vector\n",
        "\n",
        "    def forward(self, x):\n",
        "        # average pooling over a 2x2 window\n",
        "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.sigmoid(self.fc1(x)) # linear + sig activation\n",
        "        x = F.sigmoid(self.fc2(x)) # linear + sig activation\n",
        "        x = self.fc3(x) # linear\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BxZoUpss4Pz"
      },
      "source": [
        "In general, a PyTorch neural network definition must:\n",
        "- subclass [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "- call `super().__init__()` in the constructor (`__init__()`) method\n",
        "- define the trainable parameters/layers (convolutions, linears, poolings, etc.) in the constructor\n",
        "- define what should happen to the inputs in the `forward()` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wdp9RkPobRuC"
      },
      "outputs": [],
      "source": [
        "# Create your own model for the MNIST data here [20 pts]:\n",
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        # First convolutional layer taking 1 input channel (grayscale image) and producing 32 output channels\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        # Second convolutional layer taking 32 input channels and producing 64 output channels\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        # First fully connected layer: flattening the output of the conv2 to feed into this layer\n",
        "        self.fc1 = nn.Linear(7*7*64, 1024)\n",
        "        # Second fully connected layer that outputs 10 classes for MNIST digits (0-9)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply ReLU activation function after first convolution and then max pooling\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        # Apply ReLU activation function after second convolution and then max pooling\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        # Flatten the tensor for feeding into fully connected layers\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        # Apply ReLU activation function after first fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Output layer with log softmax activation to get probability distribution over 10 classes\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8GCyZDZ6iPv"
      },
      "outputs": [],
      "source": [
        "# Create your own model for the CIFAR10 data here [20 pts]:\n",
        "class CIFAR10Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10Net, self).__init__()\n",
        "        # First convolutional layer with 3 input channels (RGB image) and 64 output channels\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2)\n",
        "        # Second convolutional layer with 64 input channels and 128 output channels\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)\n",
        "        # Adding a third convolutional layer\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2)\n",
        "        # Adding a fourth convolutional layer\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "\n",
        "        # Max pooling layer that will be used after each convolutional layer\n",
        "        #self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        # Overlapping pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Dummy forward pass to determine the size of the feature map before the first fully connected layer\n",
        "        dummy_input = torch.autograd.Variable(torch.zeros(1, 3, 32, 32))  # Assuming CIFAR10 images are 32x32\n",
        "        dummy_output = self.pool(self.conv4(self.pool(self.conv3(self.pool(self.conv2(self.pool(self.conv1(dummy_input))))))))\n",
        "        self.final_feature_map_size = dummy_output.size(-1) * dummy_output.size(-2) * dummy_output.size(-3)\n",
        "\n",
        "        # First fully connected layer: flattening the output of conv2 to feed into this layer\n",
        "        self.fc1 = nn.Linear(self.final_feature_map_size, 1024)\n",
        "        # Second fully connected layer\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        # Third fully connected layer that outputs 10 classes for CIFAR10\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply ReLU activation function after first convolution and then apply max pooling\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "        # Apply ReLU activation function after second convolution and then apply max pooling\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        # Apply ReLU activation function after Thrid, fourth, and fifth convolution and then apply max pooling\n",
        "        x = F.relu(self.pool(self.conv3(x)))\n",
        "        x = F.relu(self.pool(self.conv4(x)))\n",
        "\n",
        "        # Flatten the tensor for feeding into fully connected layers\n",
        "        x = x.view(-1, self.final_feature_map_size)\n",
        "        # Apply ReLU activation function after first and second fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Output layer with log softmax activation to get probability distribution over 10 classes\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk8hMo_vxzhf"
      },
      "source": [
        "Below is a useful object for tracking losses/performance during training and dev."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ar5E7QTSw56k"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "\n",
        "    \"\"\"Computes and stores an average and current value.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq2ZTU4-19Hi"
      },
      "source": [
        "We'll define an accuracy metric that flexibly computes top-k accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "er1n5plIlT86"
      },
      "outputs": [],
      "source": [
        "def error_rate(output, target, topk=(1,)):\n",
        "\n",
        "    \"\"\"Computes the top-k error rate for the specified values of k.\"\"\"\n",
        "\n",
        "    maxk = max(topk) # largest k we'll need to work with\n",
        "    batch_size = target.size(0) # determine batch size\n",
        "\n",
        "    # get maxk best predictions for each item in the batch, both values and indices\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "\n",
        "    # reshape predictions and targets and compare them element-wise\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk: # for each top-k accuracy we want\n",
        "\n",
        "        # num correct\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        # num incorrect\n",
        "        wrong_k = batch_size - correct_k\n",
        "        # as a percentage\n",
        "        res.append(wrong_k.mul_(100.0 / batch_size))\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p15LFjPHx6Wd"
      },
      "source": [
        "If you connect to a runtime with a T4 available, this line will ensure computations that can be done on the T4 are done there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xaru9TTXbAAG"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8WU1ms3yszg"
      },
      "source": [
        "The training function below takes the training set's `DataLoader`, the model we are training, the loss function we are using, and the optimizer for this model.\n",
        "\n",
        "It then trains the model on the data for 1 epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kFMDxaNDlRw0"
      },
      "outputs": [],
      "source": [
        "# training function - 1 epoch\n",
        "def train(\n",
        "    train_loader,\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    epoch,\n",
        "    epochs,\n",
        "    print_freq = 100,\n",
        "    verbose = True\n",
        "):\n",
        "\n",
        "    # track average and worst losses\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # set training mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over data - automatically shuffled\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # put batch of image tensors on GPU\n",
        "        images = images.to(device)\n",
        "        # put batch of label tensors on GPU\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # model output\n",
        "        outputs = model(images)\n",
        "\n",
        "        # loss computation\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # back propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # update meter with the value of the loss once for each item in the batch\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "\n",
        "        # logging during epoch\n",
        "        if i % print_freq == 0 and verbose == True:\n",
        "            print(\n",
        "                f'Epoch: [{epoch+1}/{epochs}][{i:4}/{len(train_loader)}]\\t'\n",
        "                f'Loss: {losses.val:.4f} ({losses.avg:.4f} on avg)'\n",
        "            )\n",
        "\n",
        "    # log again at end of epoch\n",
        "    print(f'\\n* Epoch: [{epoch+1}/{epochs}]\\tTrain loss: {losses.avg:.3f}\\n')\n",
        "\n",
        "    return losses.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DDJnoe7Pu5ez"
      },
      "outputs": [],
      "source": [
        "# val function\n",
        "def validate(\n",
        "    val_loader,\n",
        "    model,\n",
        "    criterion,\n",
        "    epoch,\n",
        "    epochs,\n",
        "    print_freq = 100,\n",
        "    verbose = True\n",
        "):\n",
        "\n",
        "    # track average and worst losses and batch-wise top-1 and top-5 accuracies\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # set evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # iterate over data - automatically shuffled\n",
        "    for i, (images, labels) in enumerate(val_loader):\n",
        "\n",
        "        # put batch of image tensors on GPU\n",
        "        images = images.to(device)\n",
        "        # put batch of label tensors on GPU\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # model output\n",
        "        output = model(images)\n",
        "\n",
        "        # loss computation\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # top-1 and top-5 accuracy on this batch\n",
        "        err1, err5, = error_rate(output.data, labels, topk=(1, 5))\n",
        "\n",
        "        # update meters with the value of the loss once for each item in the batch\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        # update meters with top-1 and top-5 accuracy on this batch once for each item in the batch\n",
        "        top1.update(err1.item(), images.size(0))\n",
        "        top5.update(err5.item(), images.size(0))\n",
        "\n",
        "        # logging during epoch\n",
        "        if i % print_freq == 0 and verbose == True:\n",
        "            print(\n",
        "                f'Test (on val set): [{epoch+1}/{epochs}][{i:4}/{len(val_loader)}]\\t'\n",
        "                f'Loss: {losses.val:.4f} ({losses.avg:.4f} on avg)\\t'\n",
        "                f'Top-1 err: {top1.val:.4f} ({top1.avg:.4f} on avg)\\t'\n",
        "                f'Top-5 err: {top5.val:.4f} ({top5.avg:.4f} on avg)'\n",
        "            )\n",
        "\n",
        "    # logging for end of epoch\n",
        "    print(\n",
        "        f'\\n* Epoch: [{epoch+1}/{epochs}]\\t'\n",
        "        f'Test loss: {losses.avg:.3f}\\t'\n",
        "        f'Top-1 err: {top1.avg:.3f}\\t'\n",
        "        f'Top-5 err: {top5.avg:.3f}\\n'\n",
        "    )\n",
        "\n",
        "    # avergae top-1 and top-5 accuracies batch-wise, and average loss batch-wise\n",
        "    return top1.avg, top5.avg, losses.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AKwJjLLU11vg"
      },
      "outputs": [],
      "source": [
        "# best error rates so far\n",
        "best_err1 = 100\n",
        "best_err5 = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGxrBqkt0IsB",
        "outputId": "bd8105fd-f372-40d7-f44d-c3d2ef67e1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/10][   0/1563]\tLoss: 2.3060 (2.3060 on avg)\n",
            "Epoch: [1/10][ 100/1563]\tLoss: 2.3057 (2.3020 on avg)\n",
            "Epoch: [1/10][ 200/1563]\tLoss: 2.3058 (2.3023 on avg)\n",
            "Epoch: [1/10][ 300/1563]\tLoss: 2.3025 (2.3020 on avg)\n",
            "Epoch: [1/10][ 400/1563]\tLoss: 2.2998 (2.3016 on avg)\n",
            "Epoch: [1/10][ 500/1563]\tLoss: 2.3023 (2.3012 on avg)\n",
            "Epoch: [1/10][ 600/1563]\tLoss: 2.2948 (2.3006 on avg)\n",
            "Epoch: [1/10][ 700/1563]\tLoss: 2.2985 (2.2999 on avg)\n",
            "Epoch: [1/10][ 800/1563]\tLoss: 2.2892 (2.2989 on avg)\n",
            "Epoch: [1/10][ 900/1563]\tLoss: 2.2742 (2.2973 on avg)\n",
            "Epoch: [1/10][1000/1563]\tLoss: 2.2543 (2.2944 on avg)\n",
            "Epoch: [1/10][1100/1563]\tLoss: 2.1502 (2.2865 on avg)\n",
            "Epoch: [1/10][1200/1563]\tLoss: 2.0576 (2.2707 on avg)\n",
            "Epoch: [1/10][1300/1563]\tLoss: 1.9634 (2.2526 on avg)\n",
            "Epoch: [1/10][1400/1563]\tLoss: 1.9403 (2.2350 on avg)\n",
            "Epoch: [1/10][1500/1563]\tLoss: 2.0529 (2.2175 on avg)\n",
            "\n",
            "* Epoch: [1/10]\tTrain loss: 2.208\n",
            "\n",
            "Test (on val set): [1/10][   0/313]\tLoss: 2.0678 (2.0678 on avg)\tTop-1 err: 78.1250 (78.1250 on avg)\tTop-5 err: 18.7500 (18.7500 on avg)\n",
            "Test (on val set): [1/10][ 100/313]\tLoss: 1.7745 (1.9057 on avg)\tTop-1 err: 71.8750 (73.3911 on avg)\tTop-5 err: 12.5000 (16.5223 on avg)\n",
            "Test (on val set): [1/10][ 200/313]\tLoss: 1.9469 (1.9129 on avg)\tTop-1 err: 78.1250 (74.3159 on avg)\tTop-5 err: 21.8750 (16.6200 on avg)\n",
            "Test (on val set): [1/10][ 300/313]\tLoss: 1.8871 (1.9162 on avg)\tTop-1 err: 78.1250 (74.2525 on avg)\tTop-5 err: 9.3750 (16.4971 on avg)\n",
            "\n",
            "* Epoch: [1/10]\tTest loss: 1.917\tTop-1 err: 74.350\tTop-5 err: 16.500\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 74.35 16.5 \n",
            "\n",
            "Epoch: [2/10][   0/1563]\tLoss: 1.9557 (1.9557 on avg)\n",
            "Epoch: [2/10][ 100/1563]\tLoss: 1.7923 (1.9012 on avg)\n",
            "Epoch: [2/10][ 200/1563]\tLoss: 1.9898 (1.8955 on avg)\n",
            "Epoch: [2/10][ 300/1563]\tLoss: 1.7454 (1.8799 on avg)\n",
            "Epoch: [2/10][ 400/1563]\tLoss: 1.8720 (1.8663 on avg)\n",
            "Epoch: [2/10][ 500/1563]\tLoss: 1.9002 (1.8523 on avg)\n",
            "Epoch: [2/10][ 600/1563]\tLoss: 1.6818 (1.8376 on avg)\n",
            "Epoch: [2/10][ 700/1563]\tLoss: 1.8279 (1.8228 on avg)\n",
            "Epoch: [2/10][ 800/1563]\tLoss: 1.8450 (1.8127 on avg)\n",
            "Epoch: [2/10][ 900/1563]\tLoss: 1.6568 (1.8019 on avg)\n",
            "Epoch: [2/10][1000/1563]\tLoss: 1.6976 (1.7890 on avg)\n",
            "Epoch: [2/10][1100/1563]\tLoss: 1.5977 (1.7788 on avg)\n",
            "Epoch: [2/10][1200/1563]\tLoss: 1.4998 (1.7688 on avg)\n",
            "Epoch: [2/10][1300/1563]\tLoss: 1.8716 (1.7582 on avg)\n",
            "Epoch: [2/10][1400/1563]\tLoss: 1.8710 (1.7480 on avg)\n",
            "Epoch: [2/10][1500/1563]\tLoss: 1.5479 (1.7367 on avg)\n",
            "\n",
            "* Epoch: [2/10]\tTrain loss: 1.731\n",
            "\n",
            "Test (on val set): [2/10][   0/313]\tLoss: 1.7676 (1.7676 on avg)\tTop-1 err: 71.8750 (71.8750 on avg)\tTop-5 err: 6.2500 (6.2500 on avg)\n",
            "Test (on val set): [2/10][ 100/313]\tLoss: 1.6462 (1.5800 on avg)\tTop-1 err: 62.5000 (60.2413 on avg)\tTop-5 err: 15.6250 (8.5396 on avg)\n",
            "Test (on val set): [2/10][ 200/313]\tLoss: 1.6773 (1.5685 on avg)\tTop-1 err: 68.7500 (59.4061 on avg)\tTop-5 err: 12.5000 (8.9397 on avg)\n",
            "Test (on val set): [2/10][ 300/313]\tLoss: 1.4369 (1.5678 on avg)\tTop-1 err: 56.2500 (59.0428 on avg)\tTop-5 err: 3.1250 (8.8144 on avg)\n",
            "\n",
            "* Epoch: [2/10]\tTest loss: 1.564\tTop-1 err: 58.900\tTop-5 err: 8.730\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 58.9 8.73 \n",
            "\n",
            "Epoch: [3/10][   0/1563]\tLoss: 1.6039 (1.6039 on avg)\n",
            "Epoch: [3/10][ 100/1563]\tLoss: 1.7203 (1.5359 on avg)\n",
            "Epoch: [3/10][ 200/1563]\tLoss: 1.5067 (1.5385 on avg)\n",
            "Epoch: [3/10][ 300/1563]\tLoss: 1.4318 (1.5408 on avg)\n",
            "Epoch: [3/10][ 400/1563]\tLoss: 1.5007 (1.5370 on avg)\n",
            "Epoch: [3/10][ 500/1563]\tLoss: 1.3391 (1.5365 on avg)\n",
            "Epoch: [3/10][ 600/1563]\tLoss: 1.7715 (1.5317 on avg)\n",
            "Epoch: [3/10][ 700/1563]\tLoss: 1.6800 (1.5269 on avg)\n",
            "Epoch: [3/10][ 800/1563]\tLoss: 1.5394 (1.5184 on avg)\n",
            "Epoch: [3/10][ 900/1563]\tLoss: 1.3318 (1.5088 on avg)\n",
            "Epoch: [3/10][1000/1563]\tLoss: 1.5283 (1.4979 on avg)\n",
            "Epoch: [3/10][1100/1563]\tLoss: 1.8233 (1.4928 on avg)\n",
            "Epoch: [3/10][1200/1563]\tLoss: 1.6474 (1.4865 on avg)\n",
            "Epoch: [3/10][1300/1563]\tLoss: 1.5331 (1.4802 on avg)\n",
            "Epoch: [3/10][1400/1563]\tLoss: 1.9003 (1.4733 on avg)\n",
            "Epoch: [3/10][1500/1563]\tLoss: 1.3238 (1.4652 on avg)\n",
            "\n",
            "* Epoch: [3/10]\tTrain loss: 1.461\n",
            "\n",
            "Test (on val set): [3/10][   0/313]\tLoss: 1.2256 (1.2256 on avg)\tTop-1 err: 40.6250 (40.6250 on avg)\tTop-5 err: 3.1250 (3.1250 on avg)\n",
            "Test (on val set): [3/10][ 100/313]\tLoss: 1.5646 (1.3672 on avg)\tTop-1 err: 53.1250 (51.0210 on avg)\tTop-5 err: 6.2500 (5.9406 on avg)\n",
            "Test (on val set): [3/10][ 200/313]\tLoss: 1.3862 (1.3606 on avg)\tTop-1 err: 53.1250 (50.3731 on avg)\tTop-5 err: 3.1250 (6.0323 on avg)\n",
            "Test (on val set): [3/10][ 300/313]\tLoss: 1.3504 (1.3583 on avg)\tTop-1 err: 46.8750 (50.4568 on avg)\tTop-5 err: 6.2500 (6.1047 on avg)\n",
            "\n",
            "* Epoch: [3/10]\tTest loss: 1.358\tTop-1 err: 50.470\tTop-5 err: 6.100\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 50.47 6.1 \n",
            "\n",
            "Epoch: [4/10][   0/1563]\tLoss: 1.5297 (1.5297 on avg)\n",
            "Epoch: [4/10][ 100/1563]\tLoss: 1.3157 (1.3371 on avg)\n",
            "Epoch: [4/10][ 200/1563]\tLoss: 1.4262 (1.3405 on avg)\n",
            "Epoch: [4/10][ 300/1563]\tLoss: 1.2329 (1.3301 on avg)\n",
            "Epoch: [4/10][ 400/1563]\tLoss: 1.3214 (1.3140 on avg)\n",
            "Epoch: [4/10][ 500/1563]\tLoss: 1.4654 (1.3111 on avg)\n",
            "Epoch: [4/10][ 600/1563]\tLoss: 1.4890 (1.3102 on avg)\n",
            "Epoch: [4/10][ 700/1563]\tLoss: 1.7241 (1.2997 on avg)\n",
            "Epoch: [4/10][ 800/1563]\tLoss: 1.2085 (1.2931 on avg)\n",
            "Epoch: [4/10][ 900/1563]\tLoss: 1.1340 (1.2860 on avg)\n",
            "Epoch: [4/10][1000/1563]\tLoss: 1.5005 (1.2785 on avg)\n",
            "Epoch: [4/10][1100/1563]\tLoss: 1.2457 (1.2736 on avg)\n",
            "Epoch: [4/10][1200/1563]\tLoss: 1.5556 (1.2663 on avg)\n",
            "Epoch: [4/10][1300/1563]\tLoss: 1.2911 (1.2583 on avg)\n",
            "Epoch: [4/10][1400/1563]\tLoss: 1.1427 (1.2536 on avg)\n",
            "Epoch: [4/10][1500/1563]\tLoss: 1.3057 (1.2485 on avg)\n",
            "\n",
            "* Epoch: [4/10]\tTrain loss: 1.244\n",
            "\n",
            "Test (on val set): [4/10][   0/313]\tLoss: 1.1245 (1.1245 on avg)\tTop-1 err: 43.7500 (43.7500 on avg)\tTop-5 err: 3.1250 (3.1250 on avg)\n",
            "Test (on val set): [4/10][ 100/313]\tLoss: 1.3149 (1.1534 on avg)\tTop-1 err: 46.8750 (41.5532 on avg)\tTop-5 err: 9.3750 (4.0842 on avg)\n",
            "Test (on val set): [4/10][ 200/313]\tLoss: 1.0843 (1.1493 on avg)\tTop-1 err: 37.5000 (41.2624 on avg)\tTop-5 err: 6.2500 (4.1978 on avg)\n",
            "Test (on val set): [4/10][ 300/313]\tLoss: 1.3537 (1.1413 on avg)\tTop-1 err: 46.8750 (41.3102 on avg)\tTop-5 err: 3.1250 (3.9971 on avg)\n",
            "\n",
            "* Epoch: [4/10]\tTest loss: 1.141\tTop-1 err: 41.360\tTop-5 err: 3.990\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 41.36 3.99 \n",
            "\n",
            "Epoch: [5/10][   0/1563]\tLoss: 1.1346 (1.1346 on avg)\n",
            "Epoch: [5/10][ 100/1563]\tLoss: 1.1270 (1.1046 on avg)\n",
            "Epoch: [5/10][ 200/1563]\tLoss: 1.1147 (1.1234 on avg)\n",
            "Epoch: [5/10][ 300/1563]\tLoss: 1.2555 (1.1192 on avg)\n",
            "Epoch: [5/10][ 400/1563]\tLoss: 1.1320 (1.1183 on avg)\n",
            "Epoch: [5/10][ 500/1563]\tLoss: 1.0779 (1.1221 on avg)\n",
            "Epoch: [5/10][ 600/1563]\tLoss: 1.0466 (1.1177 on avg)\n",
            "Epoch: [5/10][ 700/1563]\tLoss: 1.1075 (1.1166 on avg)\n",
            "Epoch: [5/10][ 800/1563]\tLoss: 0.8119 (1.1129 on avg)\n",
            "Epoch: [5/10][ 900/1563]\tLoss: 1.0600 (1.1074 on avg)\n",
            "Epoch: [5/10][1000/1563]\tLoss: 0.9658 (1.1003 on avg)\n",
            "Epoch: [5/10][1100/1563]\tLoss: 1.0645 (1.0970 on avg)\n",
            "Epoch: [5/10][1200/1563]\tLoss: 1.3778 (1.0946 on avg)\n",
            "Epoch: [5/10][1300/1563]\tLoss: 1.1260 (1.0904 on avg)\n",
            "Epoch: [5/10][1400/1563]\tLoss: 0.9446 (1.0849 on avg)\n",
            "Epoch: [5/10][1500/1563]\tLoss: 0.9708 (1.0803 on avg)\n",
            "\n",
            "* Epoch: [5/10]\tTrain loss: 1.079\n",
            "\n",
            "Test (on val set): [5/10][   0/313]\tLoss: 1.1296 (1.1296 on avg)\tTop-1 err: 43.7500 (43.7500 on avg)\tTop-5 err: 6.2500 (6.2500 on avg)\n",
            "Test (on val set): [5/10][ 100/313]\tLoss: 1.1758 (1.0867 on avg)\tTop-1 err: 43.7500 (39.6968 on avg)\tTop-5 err: 3.1250 (3.0322 on avg)\n",
            "Test (on val set): [5/10][ 200/313]\tLoss: 0.9928 (1.0843 on avg)\tTop-1 err: 34.3750 (39.7544 on avg)\tTop-5 err: 0.0000 (3.1095 on avg)\n",
            "Test (on val set): [5/10][ 300/313]\tLoss: 1.1269 (1.0892 on avg)\tTop-1 err: 43.7500 (39.8463 on avg)\tTop-5 err: 3.1250 (3.2392 on avg)\n",
            "\n",
            "* Epoch: [5/10]\tTest loss: 1.087\tTop-1 err: 39.860\tTop-5 err: 3.210\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 39.86 3.21 \n",
            "\n",
            "Epoch: [6/10][   0/1563]\tLoss: 1.1112 (1.1112 on avg)\n",
            "Epoch: [6/10][ 100/1563]\tLoss: 1.0904 (0.9658 on avg)\n",
            "Epoch: [6/10][ 200/1563]\tLoss: 0.9059 (0.9673 on avg)\n",
            "Epoch: [6/10][ 300/1563]\tLoss: 0.7930 (0.9664 on avg)\n",
            "Epoch: [6/10][ 400/1563]\tLoss: 1.1770 (0.9620 on avg)\n",
            "Epoch: [6/10][ 500/1563]\tLoss: 0.9497 (0.9609 on avg)\n",
            "Epoch: [6/10][ 600/1563]\tLoss: 0.8962 (0.9586 on avg)\n",
            "Epoch: [6/10][ 700/1563]\tLoss: 0.9892 (0.9593 on avg)\n",
            "Epoch: [6/10][ 800/1563]\tLoss: 0.6613 (0.9551 on avg)\n",
            "Epoch: [6/10][ 900/1563]\tLoss: 0.8928 (0.9507 on avg)\n",
            "Epoch: [6/10][1000/1563]\tLoss: 0.9846 (0.9478 on avg)\n",
            "Epoch: [6/10][1100/1563]\tLoss: 1.0648 (0.9425 on avg)\n",
            "Epoch: [6/10][1200/1563]\tLoss: 1.1161 (0.9396 on avg)\n",
            "Epoch: [6/10][1300/1563]\tLoss: 0.9443 (0.9364 on avg)\n",
            "Epoch: [6/10][1400/1563]\tLoss: 1.1818 (0.9331 on avg)\n",
            "Epoch: [6/10][1500/1563]\tLoss: 0.6388 (0.9297 on avg)\n",
            "\n",
            "* Epoch: [6/10]\tTrain loss: 0.930\n",
            "\n",
            "Test (on val set): [6/10][   0/313]\tLoss: 0.9154 (0.9154 on avg)\tTop-1 err: 34.3750 (34.3750 on avg)\tTop-5 err: 3.1250 (3.1250 on avg)\n",
            "Test (on val set): [6/10][ 100/313]\tLoss: 1.1025 (0.8944 on avg)\tTop-1 err: 46.8750 (32.0854 on avg)\tTop-5 err: 3.1250 (2.1968 on avg)\n",
            "Test (on val set): [6/10][ 200/313]\tLoss: 1.0290 (0.8849 on avg)\tTop-1 err: 37.5000 (31.9341 on avg)\tTop-5 err: 6.2500 (2.1300 on avg)\n",
            "Test (on val set): [6/10][ 300/313]\tLoss: 0.6082 (0.8882 on avg)\tTop-1 err: 25.0000 (31.7276 on avg)\tTop-5 err: 3.1250 (2.3152 on avg)\n",
            "\n",
            "* Epoch: [6/10]\tTest loss: 0.889\tTop-1 err: 31.800\tTop-5 err: 2.300\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 31.8 2.3 \n",
            "\n",
            "Epoch: [7/10][   0/1563]\tLoss: 0.5051 (0.5051 on avg)\n",
            "Epoch: [7/10][ 100/1563]\tLoss: 1.0063 (0.8279 on avg)\n",
            "Epoch: [7/10][ 200/1563]\tLoss: 0.8131 (0.8281 on avg)\n",
            "Epoch: [7/10][ 300/1563]\tLoss: 0.7905 (0.8240 on avg)\n",
            "Epoch: [7/10][ 400/1563]\tLoss: 0.8717 (0.8149 on avg)\n",
            "Epoch: [7/10][ 500/1563]\tLoss: 1.1079 (0.8224 on avg)\n",
            "Epoch: [7/10][ 600/1563]\tLoss: 0.7925 (0.8178 on avg)\n",
            "Epoch: [7/10][ 700/1563]\tLoss: 0.6540 (0.8215 on avg)\n",
            "Epoch: [7/10][ 800/1563]\tLoss: 0.7562 (0.8179 on avg)\n",
            "Epoch: [7/10][ 900/1563]\tLoss: 0.9389 (0.8155 on avg)\n",
            "Epoch: [7/10][1000/1563]\tLoss: 1.2900 (0.8180 on avg)\n",
            "Epoch: [7/10][1100/1563]\tLoss: 0.8219 (0.8141 on avg)\n",
            "Epoch: [7/10][1200/1563]\tLoss: 1.0212 (0.8102 on avg)\n",
            "Epoch: [7/10][1300/1563]\tLoss: 0.8313 (0.8067 on avg)\n",
            "Epoch: [7/10][1400/1563]\tLoss: 0.7263 (0.8042 on avg)\n",
            "Epoch: [7/10][1500/1563]\tLoss: 1.0862 (0.8036 on avg)\n",
            "\n",
            "* Epoch: [7/10]\tTrain loss: 0.802\n",
            "\n",
            "Test (on val set): [7/10][   0/313]\tLoss: 0.7296 (0.7296 on avg)\tTop-1 err: 31.2500 (31.2500 on avg)\tTop-5 err: 0.0000 (0.0000 on avg)\n",
            "Test (on val set): [7/10][ 100/313]\tLoss: 0.7680 (0.8210 on avg)\tTop-1 err: 28.1250 (28.4653 on avg)\tTop-5 err: 3.1250 (2.3205 on avg)\n",
            "Test (on val set): [7/10][ 200/313]\tLoss: 0.8123 (0.8005 on avg)\tTop-1 err: 31.2500 (27.7052 on avg)\tTop-5 err: 0.0000 (2.1300 on avg)\n",
            "Test (on val set): [7/10][ 300/313]\tLoss: 0.8520 (0.8043 on avg)\tTop-1 err: 34.3750 (27.6059 on avg)\tTop-5 err: 0.0000 (2.1595 on avg)\n",
            "\n",
            "* Epoch: [7/10]\tTest loss: 0.804\tTop-1 err: 27.610\tTop-5 err: 2.140\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 27.61 2.14 \n",
            "\n",
            "Epoch: [8/10][   0/1563]\tLoss: 0.7318 (0.7318 on avg)\n",
            "Epoch: [8/10][ 100/1563]\tLoss: 0.5350 (0.7072 on avg)\n",
            "Epoch: [8/10][ 200/1563]\tLoss: 0.7585 (0.7088 on avg)\n",
            "Epoch: [8/10][ 300/1563]\tLoss: 0.4512 (0.7026 on avg)\n",
            "Epoch: [8/10][ 400/1563]\tLoss: 0.6941 (0.7029 on avg)\n",
            "Epoch: [8/10][ 500/1563]\tLoss: 0.7585 (0.7071 on avg)\n",
            "Epoch: [8/10][ 600/1563]\tLoss: 0.8174 (0.7081 on avg)\n",
            "Epoch: [8/10][ 700/1563]\tLoss: 0.7392 (0.7055 on avg)\n",
            "Epoch: [8/10][ 800/1563]\tLoss: 0.8526 (0.7074 on avg)\n",
            "Epoch: [8/10][ 900/1563]\tLoss: 0.5951 (0.7080 on avg)\n",
            "Epoch: [8/10][1000/1563]\tLoss: 0.5137 (0.7083 on avg)\n",
            "Epoch: [8/10][1100/1563]\tLoss: 0.8268 (0.7088 on avg)\n",
            "Epoch: [8/10][1200/1563]\tLoss: 0.9512 (0.7069 on avg)\n",
            "Epoch: [8/10][1300/1563]\tLoss: 0.6869 (0.7047 on avg)\n",
            "Epoch: [8/10][1400/1563]\tLoss: 0.8207 (0.7009 on avg)\n",
            "Epoch: [8/10][1500/1563]\tLoss: 0.8250 (0.6995 on avg)\n",
            "\n",
            "* Epoch: [8/10]\tTrain loss: 0.697\n",
            "\n",
            "Test (on val set): [8/10][   0/313]\tLoss: 0.7475 (0.7475 on avg)\tTop-1 err: 34.3750 (34.3750 on avg)\tTop-5 err: 0.0000 (0.0000 on avg)\n",
            "Test (on val set): [8/10][ 100/313]\tLoss: 0.7011 (0.8359 on avg)\tTop-1 err: 28.1250 (29.2698 on avg)\tTop-5 err: 0.0000 (2.3205 on avg)\n",
            "Test (on val set): [8/10][ 200/313]\tLoss: 0.7848 (0.8209 on avg)\tTop-1 err: 25.0000 (28.1095 on avg)\tTop-5 err: 0.0000 (2.3010 on avg)\n",
            "Test (on val set): [8/10][ 300/313]\tLoss: 0.6123 (0.8081 on avg)\tTop-1 err: 25.0000 (27.7201 on avg)\tTop-5 err: 0.0000 (2.2841 on avg)\n",
            "\n",
            "* Epoch: [8/10]\tTest loss: 0.805\tTop-1 err: 27.530\tTop-5 err: 2.250\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 27.53 2.25 \n",
            "\n",
            "Epoch: [9/10][   0/1563]\tLoss: 0.7681 (0.7681 on avg)\n",
            "Epoch: [9/10][ 100/1563]\tLoss: 0.6599 (0.6185 on avg)\n",
            "Epoch: [9/10][ 200/1563]\tLoss: 0.7102 (0.6283 on avg)\n",
            "Epoch: [9/10][ 300/1563]\tLoss: 0.5884 (0.6192 on avg)\n",
            "Epoch: [9/10][ 400/1563]\tLoss: 0.5945 (0.6107 on avg)\n",
            "Epoch: [9/10][ 500/1563]\tLoss: 0.5807 (0.6169 on avg)\n",
            "Epoch: [9/10][ 600/1563]\tLoss: 0.5459 (0.6128 on avg)\n",
            "Epoch: [9/10][ 700/1563]\tLoss: 0.7297 (0.6095 on avg)\n",
            "Epoch: [9/10][ 800/1563]\tLoss: 0.8639 (0.6123 on avg)\n",
            "Epoch: [9/10][ 900/1563]\tLoss: 0.5853 (0.6108 on avg)\n",
            "Epoch: [9/10][1000/1563]\tLoss: 0.6271 (0.6109 on avg)\n",
            "Epoch: [9/10][1100/1563]\tLoss: 0.4090 (0.6127 on avg)\n",
            "Epoch: [9/10][1200/1563]\tLoss: 0.7339 (0.6099 on avg)\n",
            "Epoch: [9/10][1300/1563]\tLoss: 0.4923 (0.6112 on avg)\n",
            "Epoch: [9/10][1400/1563]\tLoss: 0.8215 (0.6102 on avg)\n",
            "Epoch: [9/10][1500/1563]\tLoss: 0.8614 (0.6078 on avg)\n",
            "\n",
            "* Epoch: [9/10]\tTrain loss: 0.610\n",
            "\n",
            "Test (on val set): [9/10][   0/313]\tLoss: 0.6499 (0.6499 on avg)\tTop-1 err: 21.8750 (21.8750 on avg)\tTop-5 err: 3.1250 (3.1250 on avg)\n",
            "Test (on val set): [9/10][ 100/313]\tLoss: 0.6319 (0.7008 on avg)\tTop-1 err: 28.1250 (24.5978 on avg)\tTop-5 err: 0.0000 (1.7636 on avg)\n",
            "Test (on val set): [9/10][ 200/313]\tLoss: 1.0745 (0.6944 on avg)\tTop-1 err: 37.5000 (24.0672 on avg)\tTop-5 err: 0.0000 (1.7568 on avg)\n",
            "Test (on val set): [9/10][ 300/313]\tLoss: 0.5854 (0.6906 on avg)\tTop-1 err: 21.8750 (23.8476 on avg)\tTop-5 err: 3.1250 (1.7130 on avg)\n",
            "\n",
            "* Epoch: [9/10]\tTest loss: 0.692\tTop-1 err: 23.990\tTop-5 err: 1.730\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 23.99 1.73 \n",
            "\n",
            "Epoch: [10/10][   0/1563]\tLoss: 0.5457 (0.5457 on avg)\n",
            "Epoch: [10/10][ 100/1563]\tLoss: 0.2271 (0.5103 on avg)\n",
            "Epoch: [10/10][ 200/1563]\tLoss: 0.4855 (0.5029 on avg)\n",
            "Epoch: [10/10][ 300/1563]\tLoss: 0.3265 (0.5090 on avg)\n",
            "Epoch: [10/10][ 400/1563]\tLoss: 0.5015 (0.5124 on avg)\n",
            "Epoch: [10/10][ 500/1563]\tLoss: 0.3166 (0.5178 on avg)\n",
            "Epoch: [10/10][ 600/1563]\tLoss: 0.4975 (0.5196 on avg)\n",
            "Epoch: [10/10][ 700/1563]\tLoss: 0.5469 (0.5230 on avg)\n",
            "Epoch: [10/10][ 800/1563]\tLoss: 0.5091 (0.5226 on avg)\n",
            "Epoch: [10/10][ 900/1563]\tLoss: 0.4783 (0.5218 on avg)\n",
            "Epoch: [10/10][1000/1563]\tLoss: 0.3911 (0.5209 on avg)\n",
            "Epoch: [10/10][1100/1563]\tLoss: 0.6622 (0.5205 on avg)\n",
            "Epoch: [10/10][1200/1563]\tLoss: 0.7047 (0.5220 on avg)\n",
            "Epoch: [10/10][1300/1563]\tLoss: 0.4817 (0.5218 on avg)\n",
            "Epoch: [10/10][1400/1563]\tLoss: 0.6253 (0.5221 on avg)\n",
            "Epoch: [10/10][1500/1563]\tLoss: 0.4588 (0.5224 on avg)\n",
            "\n",
            "* Epoch: [10/10]\tTrain loss: 0.523\n",
            "\n",
            "Test (on val set): [10/10][   0/313]\tLoss: 0.3848 (0.3848 on avg)\tTop-1 err: 12.5000 (12.5000 on avg)\tTop-5 err: 0.0000 (0.0000 on avg)\n",
            "Test (on val set): [10/10][ 100/313]\tLoss: 0.7185 (0.7594 on avg)\tTop-1 err: 28.1250 (26.1139 on avg)\tTop-5 err: 0.0000 (1.7636 on avg)\n",
            "Test (on val set): [10/10][ 200/313]\tLoss: 0.8749 (0.7332 on avg)\tTop-1 err: 28.1250 (24.5336 on avg)\tTop-5 err: 0.0000 (1.8657 on avg)\n",
            "Test (on val set): [10/10][ 300/313]\tLoss: 0.7388 (0.7394 on avg)\tTop-1 err: 31.2500 (24.5743 on avg)\tTop-5 err: 0.0000 (1.9207 on avg)\n",
            "\n",
            "* Epoch: [10/10]\tTest loss: 0.743\tTop-1 err: 24.730\tTop-5 err: 1.930\n",
            "\n",
            "Current best error rate (top-1 and top-5 error): 23.99 1.73 \n",
            "\n",
            "Best error rate (top-1 and top-5 error): 23.99 1.73\n"
          ]
        }
      ],
      "source": [
        "# Run the main function.\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # select a model to train here (CIFAR10Net or MNISTNet)\n",
        "    model = CIFAR10Net()\n",
        "\n",
        "    # move to GPU\n",
        "    model.to(device)\n",
        "\n",
        "    # select number of epochs\n",
        "    epochs = 10\n",
        "\n",
        "    # get criterion and optimizer\n",
        "    criterion, optimizer = get_crit_and_opt(model)\n",
        "\n",
        "    # epoch loop\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        train_loss = train(\n",
        "          train_loader,\n",
        "          model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          epoch,\n",
        "          epochs\n",
        "        )\n",
        "\n",
        "        # evaluate on validation set\n",
        "        err1, err5, val_loss = validate(\n",
        "          val_loader,\n",
        "          model,\n",
        "          criterion,\n",
        "          epoch,\n",
        "          epochs\n",
        "        )\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = err1 <= best_err1\n",
        "        best_err1 = min(err1, best_err1)\n",
        "        if is_best:\n",
        "            best_err5 = err5\n",
        "\n",
        "        print('Current best error rate (top-1 and top-5 error):', best_err1, best_err5, '\\n')\n",
        "    print('Best error rate (top-1 and top-5 error):', best_err1, best_err5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6l7WQ7QnDGj",
        "outputId": "37f22a34-fba9-46cd-b8df-57b287c70bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.81      0.77      0.79      1000\n",
            "        bird       0.92      0.84      0.88      1000\n",
            "   vegetable       0.51      0.83      0.63      1000\n",
            "         dog       0.55      0.66      0.60      1000\n",
            "         cat       0.77      0.69      0.73      1000\n",
            "         car       0.90      0.42      0.57      1000\n",
            "       fruit       0.74      0.88      0.80      1000\n",
            "       train       0.91      0.72      0.80      1000\n",
            "      rabbit       0.86      0.89      0.87      1000\n",
            "        baby       0.87      0.84      0.86      1000\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.79      0.75      0.75     10000\n",
            "weighted avg       0.79      0.75      0.75     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a classification report for one model [10 pts]\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation for efficiency\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        # Move tensors to the appropriate device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass to get the model's predictions\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Convert outputs to predicted class by taking the index with the maximum score in each output row\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Append true and predicted labels to lists\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert lists to arrays for compatibility with classification_report\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "#___________________________________________________________________________________________________________________________\n",
        "\n",
        "# Assuming you have 10 classes for CIFAR10, and their names as follows:\n",
        "target_names = ['airplane', 'bird', 'vegetable', 'dog', 'cat',\n",
        "                'car', 'fruit', 'train', 'rabbit', 'baby']\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxhQ88lq_MP"
      },
      "source": [
        "Experiment Results:\n",
        "\n",
        "*   Step 1: The first trial gave me low accuracy of 58%.\n",
        "Top-1 err: 58.000\tTop-5 err: 29.390\n",
        "*   Step 2: I added 5 layers and the second trial  of 77%.\n",
        "Top-1 err: 77.000\tTop-5 err: 26.390\n",
        "*   Step 3: Add Overlapping Pooling droppping gave me:\n",
        "Top-1 err: 69.000\tTop-5 err: 13.390\n",
        "*   Step 3: adding 10 Epochs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}